<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="">
<meta name="description" content="Goal of the project This project’s goal is to make it easier for anyone to make slides that they want, in any design they want. Essentially it brings customisation to another level because people can start making slide designs if they can describe it and in wayyy less time, so that more time can be spent practising the presentation itself rather than worrying about the design of it.
Explanation of each step of the process Below will be an explanation of why I did each step, I recommend that you go through the how-to-guide first before reading on." />
<meta name="keywords" content=", 1028" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://hwingu.github.io/1028-project/posts/blogpost/" />


    <title>
        
            Creating presentation slides with Stable Diffusion and ControlNet :: hwingu  — A simple theme for Hugo
        
    </title>





<link rel="stylesheet" href="/1028-project/main.b78c3be9451dc4ca61ca377f3dc2cf2e6345a44c2bae46216a322ef366daa399.css" integrity="sha256-t4w76UUdxMphyjd/PcLPLmNFpEwrrkYhajIu82bao5k=">



    <link rel="apple-touch-icon" sizes="180x180" href="/1028-project/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/1028-project/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/1028-project/favicon-16x16.png">
    <link rel="manifest" href="/1028-project/site.webmanifest">
    <link rel="mask-icon" href="/1028-project/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="/1028-project/favicon.ico">
    <meta name="msapplication-TileColor" content="">


<meta itemprop="name" content="Creating presentation slides with Stable Diffusion and ControlNet">
<meta itemprop="description" content="Goal of the project This project’s goal is to make it easier for anyone to make slides that they want, in any design they want. Essentially it brings customisation to another level because people can start making slide designs if they can describe it and in wayyy less time, so that more time can be spent practising the presentation itself rather than worrying about the design of it.
Explanation of each step of the process Below will be an explanation of why I did each step, I recommend that you go through the how-to-guide first before reading on."><meta itemprop="datePublished" content="2023-04-19T07:44:59+01:00" />
<meta itemprop="dateModified" content="2023-04-19T07:44:59+01:00" />
<meta itemprop="wordCount" content="1765"><meta itemprop="image" content="https://hwingu.github.io/1028-project/"/>
<meta itemprop="keywords" content="1028," />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://hwingu.github.io/1028-project/"/>

<meta name="twitter:title" content="Creating presentation slides with Stable Diffusion and ControlNet"/>
<meta name="twitter:description" content="Goal of the project This project’s goal is to make it easier for anyone to make slides that they want, in any design they want. Essentially it brings customisation to another level because people can start making slide designs if they can describe it and in wayyy less time, so that more time can be spent practising the presentation itself rather than worrying about the design of it.
Explanation of each step of the process Below will be an explanation of why I did each step, I recommend that you go through the how-to-guide first before reading on."/>



    <meta property="og:title" content="Creating presentation slides with Stable Diffusion and ControlNet" />
<meta property="og:description" content="Goal of the project This project’s goal is to make it easier for anyone to make slides that they want, in any design they want. Essentially it brings customisation to another level because people can start making slide designs if they can describe it and in wayyy less time, so that more time can be spent practising the presentation itself rather than worrying about the design of it.
Explanation of each step of the process Below will be an explanation of why I did each step, I recommend that you go through the how-to-guide first before reading on." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hwingu.github.io/1028-project/posts/blogpost/" /><meta property="og:image" content="https://hwingu.github.io/1028-project/"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-19T07:44:59+01:00" />
<meta property="article:modified_time" content="2023-04-19T07:44:59+01:00" /><meta property="og:site_name" content="hwingu" />






    <meta property="article:published_time" content="2023-04-19 07:44:59 &#43;0100 BST" />











    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/1028-project/posts" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                hwingu</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="/1028-project/posts">Blog</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        9 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://hwingu.github.io/1028-project/posts/blogpost/">Creating presentation slides with Stable Diffusion and ControlNet</a>
      </h1>

      

      
        <hr />
        <aside id="toc">
          <div class="toc-title">Table of Contents</div>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#goal-of-the-project">Goal of the project</a></li>
    <li><a href="#explanation-of-each-step-of-the-process">Explanation of each step of the process</a>
      <ul>
        <li><a href="#why-stable-diffusion">Why Stable Diffusion?</a></li>
        <li><a href="#1--creating-the-prompt-and-generating-images-of-presentation-slides">1.  Creating the prompt and generating images of presentation slides</a></li>
        <li><a href="#2--removing-the-foreground-text-objects-etc">2.  Removing the foreground (text, objects, etc)</a></li>
        <li><a href="#3--upscaling-the-background">3.  Upscaling the background</a></li>
        <li><a href="#4--apply-background-to-presentation-slide">4.  Apply background to presentation slide</a></li>
      </ul>
    </li>
    <li><a href="#interesting-things-ive-found-with-this-approach">Interesting things I&rsquo;ve found with this approach</a></li>
    <li><a href="#disadvantages-with-the-current-approach">Disadvantages with the current approach</a></li>
    <li><a href="#approaches-that-failed-but-could-work">Approaches that failed but could work</a></li>
    <li><a href="#things-i-havent-tried-yet">Things I haven’t tried yet</a></li>
  </ul>
</nav>
        </aside>
        <hr />

      

      <div class="post-content">
        <h2 id="goal-of-the-project">Goal of the project</h2>
<p>This project’s goal is to make it easier for anyone to make slides that they want, in any design they want. Essentially it brings customisation to another level because people can start making slide designs if they can describe it and in wayyy less time, so that more time can be spent practising the presentation itself rather than worrying about the design of it.</p>
<h2 id="explanation-of-each-step-of-the-process">Explanation of each step of the process</h2>
<p>Below will be an explanation of why I did each step, I recommend that you go through the <a href="http://localhost:1313/1028-site/posts/howtoguide/">how-to-guide</a> first before reading on.</p>
<h3 id="why-stable-diffusion">Why Stable Diffusion?</h3>
<p>I chose stable diffusion because</p>
<h3 id="1--creating-the-prompt-and-generating-images-of-presentation-slides">1.  Creating the prompt and generating images of presentation slides</h3>
<p><strong>Model:</strong> Deliberate_v2</p>
<p><strong>Prompt:</strong> presentation slide template, Vintage seamless pen traced print, minimalist flowers and foliage wallpaper risograph pattern white and neutral colors, greenish background, aesthetic, high quality</p>
<p><strong>Negative prompt:</strong> people, faces, distorted text, blurry, childish, messy, amateur, grainy, low-res, ugly, deformed, mangled, disproportional</p>
<p><strong>Settings:</strong> Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 2668747600, Size: 768x512, Model hash: 9aba26abdf, ControlNet-0 Enabled: True, ControlNet-0 Module: canny, ControlNet-0 Model: control_canny-fp16 [e3fe7712], ControlNet-0 Weight: 1, ControlNet-0 Guidance Start: 0, ControlNet-0 Guidance End: 1</p>
<p>dd</p>
<p><strong>ControlNet Input:</strong></p>
<p><img src="https://lh3.googleusercontent.com/jCrF-t2PezTzNIsHaR0hDZaufELKww73KrgOnmhHdAQB0EhvrYgonUJt_g6oBYSnCWGuTv_1BX0eEJ6CqIud0TY-s_2xroBYKmuElsVbDnZJuu-oHM9Xhit4EzxzUaJokOBv7F9K0UnvW2Xw22BiBK4" alt=""></p>
<p><strong>Explanation of why I used these settings:</strong> </p>
<p>The model doesn’t really matter using this method, just use any model that you like.</p>
<p>The prompt is &ldquo;Vintage seamless pen traced print, minimalist flowers and foliage wallpaper risograph pattern white and neutral colors, greenish background, aesthetic, high quality&rdquo;. Stable diffusion tend to generate better looking images when extra prompts such as aesthetic or high quality is added.</p>
<p>It is a good idea to include the background colors in the prompt. I have found that without the description of the background colours, slides tend to be more inconsistent and varied, which doesn&rsquo;t look that great when all the slides are put together.</p>
<p>The negative prompt can help with quality, the reason why I have put faces and people first is because when generating these images of slides, especially with the prompt &ldquo;professional&rdquo;. It tends to generate distorted faces of people, which is pretty creepy.</p>
<p>The prompt I used for the example above was one I copied from <a href="https://lexica.art">lexica.art</a>. I looked around on lexica.art for something that I liked and copied the prompt. <a href="https://www.reddit.com/r/StableDiffusion/">Stable diffusion Subreddit</a> and <a href="https://civitai.com">civit.ai</a> are probably better places to look for prompts though, since people there are more experienced with creating good prompt while lexica.art tends to be filled with images created by random people using the lexica model on their website.</p>
<p>the resolution is 768x512. The reason why I set it at 768x512 is so that each generation takes less time and memory, meaning that I could render more slides and have more selection of slides. I used to render my slides on 1920x1080, but in my experience, it takes a lot more time to render and takes a lot more memory, leading to memory leaks and crashes of A1111. It&rsquo;s fine to generate the image at a lower resolution at this stage because of the upscaling in the later steps. Also this means we can pump out more images at once.</p>
<p>As for the ControlNet input images, basically I have created a set of ‘blank presentation slides’ which have a solid white background, basic font and layout. The idea of this is for ControlNet to guide the layout of the slide and render the style of the slide without changing up the layout. One caveat to this approach is that the layout will completely depend on the ‘blank slides’. There will be no variation of layout to the slides rendered, which can be a good or bad thing.</p>
<p>The rest of the settings are kept default. Some things could be experimented with such as ControlNet&rsquo;s guidance strength and weight.</p>
<p><strong>Output:</strong></p>
<p><strong><img src="https://lh4.googleusercontent.com/XC7UN3L0Q-HEZl73IT563hgsRSvFp_PyQAutRhvL1tx-TRwcCM6Q8EcGFR72MmgDFXqT9XfYxgU_Ygzn-5_wNpcPRgUAoKpZ_bz6mSYtcfl5yv2yJdg6u5odMFZNCdM5tOO7M5ph5tBgmcgNPQBnkGI" alt=""></strong></p>
<blockquote>
<p>I repeated this step for each blank slide, and I also put them all in a folder for reference later on</p>
</blockquote>
<h3 id="2--removing-the-foreground-text-objects-etc">2.  Removing the foreground (text, objects, etc)</h3>
<p>Before removing the foreground, keep a copy of the original.</p>
<p><strong>If it’s a solid background (one colour):</strong> Remove the foreground using image editing tools e.g. Microsoft Paint, Photoshop, etc.</p>
<p><strong>If not:</strong> Bring the image into inpaint <strong>or</strong> Use ClipDrop’s text removal tool.</p>
<p><strong>Prompt:</strong> presentation slide template, Vintage seamless pen traced print, minimalist flowers and foliage wallpaper risograph pattern white and neutral colors, greenish background, aesthetic, high quality</p>
<p><strong>Negative prompt:</strong> people, faces, distorted text, blurry, childish, messy, amateur, grainy, low-res, ugly, deformed, mangled, disproportional</p>
<p>Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 2102601361, Size: 768x512, Model hash: 9aba26abdf, Denoising strength: 0.75, Mask blur: 4</p>
<p><strong>Explanation:</strong></p>
<p>The purpose of this step is just to remove the foreground to get the background which can be applied onto the presentation slide later on.</p>
<p>One thing to change is the denoising strength (Basically higher denoising strength, more different from original image. The denoising strength should be fairly high as we’re changing the image entirely) Fairly high is around 0.75 or higher.</p>
<p>And I kept everything else the same.</p>
<p>There have been cases where I was having trouble removing the foreground. Below is an example:</p>
<p><img src="https://lh3.googleusercontent.com/DbLUB7FSYYIXPPWSnYwEGUeN7tfN9OczzUO8D2JYkCX9f_yooLmdLUgin6B-TCcBYNJQ7X5ChXU2LSvzcyhDMl6mR6gaVfLA8G0Bb56S7yR_DZxylld1TZ9uRA6hsWtXeptlskBVdhiEotWuJnw3X0A" alt=""></p>
<p>What I did was delete the prompt completely and changed it to ‘starry lights’ which gave me this:</p>
<p><img src="https://lh5.googleusercontent.com/Isf_A_Ajn4PolYXQvOeUlMvde9UiLAqwrHwErg-YxrZUjCA3AROz33SZXAcxqWkPY_62S013Xt-sQUoimEnmNaWnylMMNXsyXFQ_Pft4o0loLi2JFGjkUNQpNyxfl2nJwONcLRbuqZfChudalItXIQQ" alt=""></p>
<h3 id="3--upscaling-the-background">3.  Upscaling the background</h3>
<p><strong>Send to img2img</strong></p>
<p><strong>Prompt:</strong> presentation slide template, Vintage seamless pen traced print, minimalist flowers and foliage wallpaper risograph pattern white and neutral colors, greenish background, aesthetic, high quality</p>
<p><strong>Negative prompt:</strong> people, faces, distorted text, blurry, childish, messy, amateur, grainy, low-res, ugly, deformed, mangled, disproportional</p>
<p>Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 68616172, Size: 1152x768, Model hash: 9aba26abdf, Denoising strength: 0.5</p>
<p><strong>Send to extras</strong></p>
<p>Postprocess upscale by: 4, Postprocess upscaler: 4x-UltraSharp</p>
<p><strong>Explanation:</strong></p>
<p>The reason why I put the image into img2img first rather than putting it to upscale in postprocess-upscale is to render a higher resolution image first. What I found was that if I put a low resolution image into post-process upscale, there will be artefacts and weird out of place shapes around the image that are very noticeable. Upscaling it first in img2img will give the image more detail, which means there will be less artefacts when post-process upscaled.</p>
<p>The resolution is 1152x768 which is 1.5x the resolution of the original image (728x512). I wanted to go for a 2x resolution but my computer specs wouldn’t allow it and kept crashing. But the results with 1.5x looked just fine.</p>
<p>The denoising strength is 0.5, it has to be low because the upscaled image has to look similar to the original. I found that 0.4 - 0.5 works fine. Any higher than 0.5 will render an image that looks completely different.</p>
<p>The post-process upscaler I used is 4x-UltraSharp. <a href="https://upscale.wiki/wiki/Model_Database">https://upscale.wiki/wiki/Model_Database</a> Link to download 4x-UltraSharp. R-ESRGAN 4x+ works fine too.</p>
<h3 id="4--apply-background-to-presentation-slide">4.  Apply background to presentation slide</h3>
<p><img src="https://lh5.googleusercontent.com/kxQdvV5VF4h1yeuI-NaiCR1EEKzbp0T0K4Z1c2vRAm6MfcXapW3Wug602hIlygMOAV3ZRC408NkbEvj9Sa2sZe27dFYre6X7qaDLAk5JI9L2S9dks_Xu_-ooMhhs2WbhdkCBJvVNGAvZ7eT_lNdhIu8" alt=""></p>
<p>I have already created all the slides in my powerpoint, so all I had to do was duplicate the slides and apply the background + customise colours for the charts</p>
<p><img src="https://lh5.googleusercontent.com/Y7ao8Ee4MlnJcCY_oeAqV_FFxTTMW1gvEdDlsFf9_IsbrNGTRKuMdI5FdoiQ3qD6LMf5xg82Dqo6kFWqtuohQh_zFBNZQ8h2fNKs2xzzWZffYmQEj8e9cOSU8YnCm232KE2DUi_rIuv7-Yu8Z-7Ip1Q" alt=""></p>
<h2 id="interesting-things-ive-found-with-this-approach">Interesting things I&rsquo;ve found with this approach</h2>
<h2 id="disadvantages-with-the-current-approach">Disadvantages with the current approach</h2>
<ol>
<li>Fonts</li>
</ol>
<p>Due to ControlNet, fonts rendered in the output image sometimes look identical to the input image. One way around this is by  inpainting the text on the original image generated on the first step, then render a new image using the same prompt. However, another problem with fonts is that fonts identified by WhatTheFont (A website that identifies font from an image) are paid. Sometimes free downloads are available when you search for the font online, but that hasn&rsquo;t been the case for all the fonts in my experience.</p>
<p>There is still no websites that does the same thing as WhatTheFont but links to fonts that are free, as far as I know.</p>
<p>Alternatively could look for free fonts that look similar on websites such as:</p>
<ul>
<li><a href="https://www.dafont.com">DaFont</a></li>
<li><a href="https://fonts.google.com">Google Fonts</a></li>
</ul>
<ol start="2">
<li>Fixed layout</li>
</ol>
<p>There is no variation with layout. The layout depends completely on the input slides.</p>
<h2 id="approaches-that-failed-but-could-work">Approaches that failed but could work</h2>
<ol>
<li>Generating everything at once</li>
</ol>
<p>This approach also uses ControlNet, but for the input image I used an image with all the slides:</p>
<p><img src="https://lh3.googleusercontent.com/Hw22SMBksxd2GPkoqS0Ca4a7YMsV1W8O9Me9dh6CM5dS71Beucs-HY8nJhvqQHEgDV1e-G0R4RubbqImlcgcsEDHjujarle980oqbuG0UQLBMg832G5EvIj3y4GEQwIeO4FYBhkqMn0vhRI7uLWVlzM" alt=""></p>
<p>This didn’t work because:</p>
<ul>
<li>The slides were too small, so less details</li>
<li>It also takes a long time to crop each of them</li>
</ul>
<p>This could work if:</p>
<ul>
<li>Somehow more details can be rendered on each slide</li>
<li>This can be done by generating a image in higher resolution, but for these I was already generating them at 1400x2700 which resulted in many crashes</li>
<li>Or some other technique, maybe with img2img</li>
<li>A script is written to crop each of the picture automatically</li>
<li>One way this could be done is using the Image.crop() function in Python PIL</li>
</ul>
<ol start="2">
<li>Asking ChatGPT to generate the prompt</li>
</ol>
<p>My previous attempt at using chatGPT for a prompt:
<a href="https://docs.google.com/document/d/1OD1Dexk3y-IJT206frdklRuWRb-BupImUn9WEr1yYw4/edit">chatgpt prompt for 1028</a></p>
<p>This approach could probably work with the right prompt, but in my experience, using the descriptions (see google doc above) that chatGPT gave didn’t really give me good results. This was using GPT-3. </p>
<ol start="3">
<li>MidJourney</li>
</ol>
<p>MidJourney had amazing results even with simple prompts using only txt2img, however my free trial ended so I couldn&rsquo;t use MidJourney anymore but I wonder what could be done using MidJourney V5.</p>
<p><strong>Example of MidJourney:</strong>
<img src="https://lh6.googleusercontent.com/nZ7bnUiGaoQARAZ4oU4qMZ2iBGdk88M_FVSXBtxlTAjCV04c7Nr1r1DIpCu9g73wvtsHCBrCfBoblG9OhfbPiI5s65VR7J_FoTDckYgGWtX-VzaeqquOpPh3WmM75bFujs0MXGgQasUggZpcB8z5cqo" alt=""><img src="https://lh6.googleusercontent.com/hT9fAF-p8-H3vahYql_8Hp8MvwL35EUO_LH9oZd-lxyYBtenL7xRyvqD7Rp1RgeJp8QL7n8ZMGlmYEBssZwoaDjAD1BPSqKcgt4NLRHZny120MybUCwif-vX9P2cOkh3JQBv7F9UJ6JSEcoWoACeLJY" alt=""></p>
<p>Definitely not perfect, but had a lot of potential.</p>
<ol start="4">
<li>img2img to generate the slides</li>
</ol>
<p>This was before ControlNet came out.</p>
<p>This approach had the same idea as the ControlNet one where I used a input image to guide SD to rendering a ppt-ish slide. Example below</p>
<pre tabindex="0"><code>Prompt: title powerpoint slide, single page, black and white, mountains in the background, clear text, professional, sleek, sharp
Negative prompt: multiple pages, people, faces, distorted text
</code></pre><p>Input image:
<img src="https://lh5.googleusercontent.com/29FnOQKPmet9oWIgqL36HkQDk0OwIVqZFs8eDLbmTTHP_-wagD1SNu7HxYyR_97OulYTDBKGTQMAzVcaV_1BJIF-cWHWKOZQCJjXy59JnXqTg3aIDYxUO35u-JLwulQX3jQuznO7plYxbn5J2l8Ehxs" alt="">
Output:
<img src="https://lh3.googleusercontent.com/dqcaa6dz0UGihcqVMuihhDEXmneb2pGlsFyJY0ybZ0tJYThW9bho5tfKER-YdyvJOTEBE4F0B-SstAg5njmNahpfuAbt2DB91atj14hq-RSzQf2d0oTQovZb4RP-Bdgxs5VsmLTFYBjjFftpXwVK6RQ" alt=""></p>
<p>The layout of the slides definitely were not as restricted as the current approach.</p>
<ol start="5">
<li>Rendering images with lora trained with presentation slides found online</li>
</ol>
<p>I trained some images of slides that I found on google:
<img src="https://lh5.googleusercontent.com/T2103shVcF7PNmvQexbUGZ4p6wy2snAO4HyEDgrI2NyTGw1_zeb9PJJ_kPU_Eie_7PcCuvgNt7S47Wu7Q7XUP3_bX3jxITg-B_qQYQ_K8kzfw3WtODDZThlvPh6WbhZPkS9DkZkXjYIR2zu2Lu0LWtA" alt=""></p>
<blockquote>
<p>The training data only consists of title slides.</p>
</blockquote>
<p><strong>Test that I did</strong></p>
<pre tabindex="0"><code>Prompt: presentation slide template, &lt;lora:last:1&gt;, tree, leaves&gt;
</code></pre><p><strong>With lora</strong>
<img src="https://lh6.googleusercontent.com/46tseX0wjN7MgzlCpkzCfgGoYdEkiuetsUvobG9kfoY-hK-xtIuEVree7QRZkf128dnUXXzBFIC-Tmul1K1NnANQX8xwqjVuZe4UkF9Lrz-3Qcz4E5HR83ewRTQIAYhnRsXi7ed1FBhixwmOQArgPJ0" alt="">
<strong>Without lora</strong>
<img src="https://lh4.googleusercontent.com/MJcdY2llZrRmtrt-3j0ukKN5t8O2mhPhcDOtwGHAjeAVyCslkB3ZRzTn2wAB4T2eDa-Q8FM4_ZOb8RWjC-hHtq2qPzxsZxecU09qAoSjg4S9PNBsB3cJcRpSznqpuBszqGhsqfMc-l6G7bnMMPPvHFA" alt=""></p>
<p>While it definitely did render a more ppt-ish slide in the example above, I&rsquo;ve tried many more tests but most of the slides doesn&rsquo;t really match the prompt or looks straight up broken.</p>
<p>If you want to try out the lora, here&rsquo;s the <a href="https://1drv.ms/u/s!App0pCtSTbcBgak1XhOgCLd5K4tkVA?e=Ko3baa">link</a></p>
<h2 id="things-i-havent-tried-yet">Things I haven’t tried yet</h2>
<ol>
<li>Supercharging the project using GPT-4 and maybe automating it</li>
</ol>
<ul>
<li>Could have GPT-4 act as a designer, and the prompter could be the customer describing what they want for the slide and their target audience. Then the slides would be done in minutes.</li>
</ul>
<ol start="2">
<li>Training a lora with a lot of ppt slides so that it could render better slides.</li>
</ol>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://hwingu.github.io/1028-project/tags/1028/">1028</a></span>
        
    </p>

      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        1765 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2023-04-19 07:44
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        
        <div class="pagination__title">
            <span class="pagination__title-h">Read other posts</span>
            <hr />
        </div>
        

        <div class="pagination__buttons">
            
            <span class="button previous">
                <a href="https://hwingu.github.io/1028-project/posts/howtoguide/">
                    <span class="button__icon">←</span>
                    <span class="button__text">How to create presentation slides with Stable Diffusion and ControlNet</span>
                </a>
            </span>
            

            
        </div>
    </div>


    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="/1028-project/bundle.min.205d491810c28f95aa953fae884e1c27abe13fdf93ec63b882d0036b248d4a6282eb2d134e4e7225c6ad6e86db87b08488a361ca4a7383d01fcff43f3d57b9c3.js" integrity="sha512-IF1JGBDCj5WqlT&#43;uiE4cJ6vhP9&#43;T7GO4gtADaySNSmKC6y0TTk5yJcatbobbh7CEiKNhykpzg9Afz/Q/PVe5ww=="></script>



    </body>
</html>
